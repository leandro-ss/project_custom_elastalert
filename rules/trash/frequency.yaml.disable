name: example_frequency

# (Optional)
# This value will be used to identify the relative priority of the alert.
# Optionally, this field can be included in any alert type 
# (e.g. for use in email subject/body text). (Optional, int, default 2)
priority: 1

# (Required)
# Type of alert.
# the frequency rule type alerts when num_events events occur with timeframe time
type: frequency

# (Required)
# Index to search, wildcard supported
index: metricbeat-*

# (Required, frequency specific)
# Alert when this many documents matching the query occur within a timeframe
num_events: 50

# (Required, frequency specific)
# num_events must occur within this amount of time to trigger an alert
timeframe:
  minutes: 5

# (Required)
# A list of Elasticsearch filters used for find events
# These filters are joined with AND and nested in a filtered query
# For more info: http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/query-dsl.html
#filter:
#- term:
#    some_field: "some_value"

# (Required)
# The alert is use when a match is found
alert:
 - debug


#use_kibana_dashboard: true

# This option is for Kibana 3 only. If true, ElastAlert will generate a temporary Kibana
# dashboard and include a link to it in alerts.
# The dashboard consists of an events over time graph and a table with include fields selected in the table. If the rule uses query_key, the dashboard will also contain a filter for the query_key of the alert. The dashboard schema will be uploaded to the
# kibana-int index as a temporary dashboard. (Optional, boolean, default False)
# generate_kibana_link: 

# I have lots of documents and it's really slow, how can I speed it up?
# There are several ways to potentially speed up queries. If you are using index: logstash-*, Elasticsearch will query all shards, even if they do not possibly contain data with the correct timestamp. Instead, you can use Python time format strings and set use_strftime_index

# index: logstash-%Y.%m
# use_strftime_index: true

#Installation instructions:
#$ git clone https://github.com/Yelp/elastalert.git
#$ cd elastalert/
#$ git checkout support_es5
#$ python setup.py install
#$ pip install -r requirements.txt


# If true, ElastAlert will make an aggregation query against Elasticsearch 
# to get counts of documents matching each unique value of query_key.
# This must be used with query_key and doc_type. This will only return a maximum
# of terms_size, default 50, unique terms.
#use_terms_query: true

# When used with use_terms_query,
# this is the maximum number of terms returned per query. Default is 50.
#terms_size: 50

# Counts of documents will be stored independently for each value of query_key.
# Only num_events documents, all with the same value of query_key, will trigger an alert.
#query_key: beat.hostname.keyword
